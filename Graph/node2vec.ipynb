{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [aditya-grover/node2vec](https://github.com/aditya-grover/node2vec/)\n",
    "\n",
    "论文笔记：[node2vec, Scalable Feature Learning for Networks Note | Yam](https://yam.gift/2020/03/30/Paper/2020-03-30-Node2Vec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "import jieba\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造数据\n",
    "\n",
    "这里用 TextRank 类似的方法构造。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sample.txt\", \"r\") as f:\n",
    "    text = f.read()[:10000]\n",
    "# text = \"我爱你，你爱我，她爱我，你爱北京天安门。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/y0/t47pd_bj3b9_3j9n_56m52gw0000gn/T/jieba.cache\n",
      "Loading model cost 1.976 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "text_list = jieba.lcut(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = defaultdict(int)\n",
    "win = 2\n",
    "num_token = len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, w in enumerate(text_list):\n",
    "    for j in range(i+1, i+win):\n",
    "        if j >= num_token:\n",
    "            break\n",
    "        cm[(w, text_list[j])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = []\n",
    "for key,value in cm.items():\n",
    "    item = (key[0], key[1], value)\n",
    "    graph_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1785, 4820)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alias_setup(probs):\n",
    "    K = len(probs)\n",
    "    q = np.zeros(K)\n",
    "    J = np.zeros(K, dtype=np.int)\n",
    "\n",
    "    smaller = []\n",
    "    larger = []\n",
    "    for kk, prob in enumerate(probs):\n",
    "        q[kk] = K*prob\n",
    "        if q[kk] < 1.0:\n",
    "            smaller.append(kk)\n",
    "        else:\n",
    "            larger.append(kk)\n",
    "\n",
    "    while len(smaller) > 0 and len(larger) > 0:\n",
    "        small = smaller.pop()\n",
    "        large = larger.pop()\n",
    "\n",
    "        J[small] = large\n",
    "        q[large] = q[large] + q[small] - 1.0\n",
    "        if q[large] < 1.0:\n",
    "            smaller.append(large)\n",
    "        else:\n",
    "            larger.append(large)\n",
    "    return J, q\n",
    "\n",
    "def alias_draw(J, q):\n",
    "    K = len(J)\n",
    "    kk = int(np.floor(np.random.rand()*K))\n",
    "    if np.random.rand() < q[kk]:\n",
    "        return kk\n",
    "    else:\n",
    "        return J[kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_nodes = {}\n",
    "for node in G.nodes():\n",
    "    unnormalized_probs = [G[node][nbr]['weight'] for nbr in sorted(G.neighbors(node))]\n",
    "    norm_const = sum(unnormalized_probs)\n",
    "    normalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "    alias_nodes[node] = alias_setup(normalized_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, q = 1, 1\n",
    "def get_alias_edge(src, dst):\n",
    "    unnormalized_probs = []\n",
    "    for dst_nbr in sorted(G.neighbors(dst)):\n",
    "        if dst_nbr == src:\n",
    "            unnormalized_probs.append(G[dst][dst_nbr]['weight']/p)\n",
    "        elif G.has_edge(dst_nbr, src):\n",
    "            unnormalized_probs.append(G[dst][dst_nbr]['weight'])\n",
    "        else:\n",
    "            unnormalized_probs.append(G[dst][dst_nbr]['weight']/q)\n",
    "    norm_const = sum(unnormalized_probs)\n",
    "    normalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "    return alias_setup(normalized_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_edges = {}\n",
    "triads = {}\n",
    "\n",
    "for edge in G.edges():\n",
    "    alias_edges[edge] = get_alias_edge(edge[0], edge[1])\n",
    "    alias_edges[(edge[1], edge[0])] = get_alias_edge(edge[1], edge[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机游走"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_walks = 10\n",
    "walk_length = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_walks(num_walks, walk_length):\n",
    "    walks = []\n",
    "    nodes = list(G.nodes())\n",
    "    print ('Walk iteration:')\n",
    "    for walk_iter in range(num_walks):\n",
    "        print (str(walk_iter+1), '/', str(num_walks))\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(walk_length=walk_length, start_node=node))\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node2vec_walk(walk_length, start_node):\n",
    "    walk = [start_node]\n",
    "    while len(walk) < walk_length:\n",
    "        cur = walk[-1]\n",
    "        cur_nbrs = sorted(G.neighbors(cur))\n",
    "        if len(cur_nbrs) > 0:\n",
    "            if len(walk) == 1:\n",
    "                walk.append(cur_nbrs[alias_draw(alias_nodes[cur][0], alias_nodes[cur][1])])\n",
    "            else:\n",
    "                prev = walk[-2]\n",
    "                nxt = cur_nbrs[alias_draw(alias_edges[(prev, cur)][0], alias_edges[(prev, cur)][1])]\n",
    "                walk.append(nxt)\n",
    "        else:\n",
    "            break\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n"
     ]
    }
   ],
   "source": [
    "walks = simulate_walks(num_walks, walk_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17850, 80)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(walks).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17850"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "dimensions = 128\n",
    "\n",
    "def learn_embeddings(walks):\n",
    "    walks = [list(map(str, walk)) for walk in walks]\n",
    "    model = Word2Vec(walks, size=dimensions, window=window_size, min_count=0, sg=1, workers=8, iter=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn_embeddings(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('问题', 0.8225580453872681),\n",
       " ('原则', 0.7723050117492676),\n",
       " ('虽难', 0.7416102290153503),\n",
       " ('讨论', 0.718680739402771),\n",
       " ('）', 0.6941202878952026),\n",
       " ('吵吵闹闹', 0.6421607732772827),\n",
       " ('社会', 0.6192087531089783),\n",
       " ('荒谬', 0.6081787943840027),\n",
       " ('之一', 0.6002324223518372),\n",
       " ('两者', 0.592690110206604)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word(\"伦理\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1785"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
